{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concurrent.futures\n",
    "https://docs.python.org/3/library/concurrent.futures.html\n",
    "\n",
    "This module makes it possible to execute callables asynchronously. This can be done either in a `ProcessPoolExecutor` (which is most suitable for CPU bound tasks because execution in separate processes is not subject to the GIL) or a `ThreadPoolExecutor` (which helps if the tasks are I/O bound). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating `Future` objects\n",
    "Both executors provide a `submit()` method that returns a `Future` for the asynchronous compuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123456789\n"
     ]
    }
   ],
   "source": [
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    future = executor.submit(int, \"123456789\")\n",
    "    assert isinstance(future, concurrent.futures.Future)\n",
    "    \n",
    "    # Wait for the asynchronous call to complete and retrieve the result\n",
    "    print(future.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speeding up CPU bound tasks with `ProcessPoolExecutor.map()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we define a simple context manager for time measurements. We could also use `%%time` or `%%timeit`, but their results are partly confusing because they cannot track the CPU usage in child processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import contextlib\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def measure_time():\n",
    "    start = time.time()\n",
    "    yield\n",
    "    end = time.time()\n",
    "    print(f\"Elapsed time: {end - start:.03} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU bound task: determine all prime factors of a given number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def factors(n):\n",
    "    assert n >= 1\n",
    "    \n",
    "    def candidates():\n",
    "        yield 2\n",
    "        sqrt_n = int(math.floor(math.sqrt(n)))\n",
    "        yield from range(3, sqrt_n + 1, 2)\n",
    "\n",
    "    def gen(n):\n",
    "        for i in candidates():\n",
    "            while n % i == 0:\n",
    "                yield i\n",
    "                n //= i\n",
    "                if n == 1:\n",
    "                    return\n",
    "        yield n\n",
    "\n",
    "    return tuple(gen(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3607, 3803)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors(123456789)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the sum of all factors of a few numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_numbers_large_prime_factors = (\n",
    "    112272535095293,\n",
    "    112582705942171,\n",
    "    112272535095293,\n",
    "    115280095190773,\n",
    "    115797848077099,\n",
    "    1099726899285419)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the factors sequentially on a single CPU core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568206055343329\n",
      "Elapsed time: 6.47 seconds.\n"
     ]
    }
   ],
   "source": [
    "with measure_time():\n",
    "    print(sum(sum(factors(n)) for n in few_numbers_large_prime_factors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make use of multiple CPU cores with `ProcessPoolExecutor.map()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568206055343329\n",
      "Elapsed time: 2.98 seconds.\n"
     ]
    }
   ],
   "source": [
    "with measure_time():\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        print(sum(sum(result) for result in executor.map(factors, few_numbers_large_prime_factors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with `ThreadPoolExecutor.map()`\n",
    "Using threads rather than processes does not provide a speed-up because Python's GIL restricts the compulation to a single CPU core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568206055343329\n",
      "Elapsed time: 7.47 seconds.\n"
     ]
    }
   ],
   "source": [
    "with measure_time():\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        print(sum(sum(result) for result in executor.map(factors, few_numbers_large_prime_factors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat the experiment with a larger set of small numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "many_small_numbers = range(1, 40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139614694\n",
      "Elapsed time: 0.322 seconds.\n"
     ]
    }
   ],
   "source": [
    "with measure_time():\n",
    "    print(sum(sum(factors(n)) for n in many_small_numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, using `ProcessPoolExecutor.map()` as above does not help because the vast majority of the numbers can be factored very quickly, such that the overhead caused by passing the arguments and results between the main process and the callables in the child processes dominates the run time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139614694\n",
      "Elapsed time: 10.8 seconds.\n"
     ]
    }
   ],
   "source": [
    "with measure_time():\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        print(sum(sum(result) for result in executor.map(factors, many_small_numbers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can use the `chunksize` argument to group the numbers into larger chunks and reduce the overhead considerably:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139614694\n",
      "Elapsed time: 0.176 seconds.\n"
     ]
    }
   ],
   "source": [
    "with measure_time():\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        print(sum(sum(result) for result in executor.map(factors, many_small_numbers, chunksize=1000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resilience against aborted child processes\n",
    "Since Python 3.2, a `BrokenProcessPool` exception is raised if one of the worker processes created by the pool dies. This cannot be seen easily in Jupyter, but at least we see that the main process is not frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frank/code/github/freininghaus/notes/venv/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def fail_sometimes(n):\n",
    "    if n % 5 == 0:\n",
    "        sys.exit(1)\n",
    "    return n\n",
    "\n",
    "try:\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        tuple(map(fail_sometimes, range(10)))\n",
    "except concurrent.futures.process.BrokenProcessPool as e:\n",
    "    print(\"You would see that a BrokenProcessPool exception is raised when trying this outside Jupyter.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do not try the same with `multiprocessing`\n",
    "In contrast, `multiprocessing.Pool.map()` will usually freeze as of October 2019 if one of the processes dies, which can cause trouble if, e.g., the kernel decides to kill one of them in out-of-memory situations: https://bugs.python.org/issue9205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "p = multiprocessing.Pool()\n",
    "\n",
    "# Replace 'False' by 'True' in the line below to see the Jupyter kernel freeze.\n",
    "if False:\n",
    "    tuple(p.map(fail_sometimes, range(10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
