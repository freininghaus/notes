{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why learn AWK?\n",
    "This notebook is inspired by a very nice series of blog posts by Jonathan Palardy that I stumbled across recently:\n",
    "* https://blog.jpalardy.com/posts/why-learn-awk/\n",
    "* https://blog.jpalardy.com/posts/awk-tutorial-part-1/\n",
    "* https://blog.jpalardy.com/posts/awk-tutorial-part-2/\n",
    "* https://blog.jpalardy.com/posts/awk-tutorial-part-3/\n",
    "* https://blog.jpalardy.com/posts/my-best-awk-tricks/\n",
    "\n",
    "Maybe it makes sense to try awk after all :-)\n",
    "\n",
    "In this notebook, I'll reproduce the examples given in the blog posts, work on the exercises, and sometimes do a bit more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#AWK-tutorial,-part-1\" data-toc-modified-id=\"AWK-tutorial,-part-1-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>AWK tutorial, part 1</a></span><ul class=\"toc-item\"><li><span><a href=\"#Download-the-example-data\" data-toc-modified-id=\"Download-the-example-data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Download the example data</a></span></li><li><span><a href=\"#Helper-functions:-cool-stuff-that-we-will-be-able-to-do-with-AWK-soon\" data-toc-modified-id=\"Helper-functions:-cool-stuff-that-we-will-be-able-to-do-with-AWK-soon-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Helper functions: cool stuff that we will be able to do with AWK soon</a></span></li><li><span><a href=\"#Printing-Columns\" data-toc-modified-id=\"Printing-Columns-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Printing Columns</a></span></li><li><span><a href=\"#Structure-of-AWK-rules\" data-toc-modified-id=\"Structure-of-AWK-rules-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Structure of AWK rules</a></span><ul class=\"toc-item\"><li><span><a href=\"#Automatic-conversions\" data-toc-modified-id=\"Automatic-conversions-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Automatic conversions</a></span></li><li><span><a href=\"#Missing-condition\" data-toc-modified-id=\"Missing-condition-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Missing condition</a></span></li><li><span><a href=\"#Missing-action\" data-toc-modified-id=\"Missing-action-1.4.3\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;</span>Missing action</a></span></li></ul></li><li><span><a href=\"#More-Printing\" data-toc-modified-id=\"More-Printing-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>More Printing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Printing-multiple-columns\" data-toc-modified-id=\"Printing-multiple-columns-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>Printing multiple columns</a></span></li><li><span><a href=\"#More-formatting-power-with-printf\" data-toc-modified-id=\"More-formatting-power-with-printf-1.5.2\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span>More formatting power with <code>printf</code></a></span></li><li><span><a href=\"#String-concatenation\" data-toc-modified-id=\"String-concatenation-1.5.3\"><span class=\"toc-item-num\">1.5.3&nbsp;&nbsp;</span>String concatenation</a></span></li></ul></li><li><span><a href=\"#Exercises\" data-toc-modified-id=\"Exercises-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Exercises</a></span><ul class=\"toc-item\"><li><span><a href=\"#Print-the-&quot;Date&quot;,-&quot;Volume&quot;,-&quot;Open&quot;,-&quot;Close&quot;-columns,-in-that-order\" data-toc-modified-id=\"Print-the-&quot;Date&quot;,-&quot;Volume&quot;,-&quot;Open&quot;,-&quot;Close&quot;-columns,-in-that-order-1.6.1\"><span class=\"toc-item-num\">1.6.1&nbsp;&nbsp;</span>Print the \"Date\", \"Volume\", \"Open\", \"Close\" columns, in that order</a></span></li><li><span><a href=\"#Only-print-lines-where-the-stock-price-increased-(&quot;Close&quot;->-&quot;Open&quot;)\" data-toc-modified-id=\"Only-print-lines-where-the-stock-price-increased-(&quot;Close&quot;->-&quot;Open&quot;)-1.6.2\"><span class=\"toc-item-num\">1.6.2&nbsp;&nbsp;</span>Only print lines where the stock price increased (\"Close\" &gt; \"Open\")</a></span></li><li><span><a href=\"#Print-the-&quot;Date&quot;-column-and-the-stock-price-difference-(&quot;Close&quot;---&quot;Open)\" data-toc-modified-id=\"Print-the-&quot;Date&quot;-column-and-the-stock-price-difference-(&quot;Close&quot;---&quot;Open)-1.6.3\"><span class=\"toc-item-num\">1.6.3&nbsp;&nbsp;</span>Print the \"Date\" column and the stock price difference (\"Close\" - \"Open)</a></span></li><li><span><a href=\"#Print-an-empty-line-between-each-line\" data-toc-modified-id=\"Print-an-empty-line-between-each-line-1.6.4\"><span class=\"toc-item-num\">1.6.4&nbsp;&nbsp;</span>Print an empty line between each line</a></span></li></ul></li></ul></li><li><span><a href=\"#AWK-tutorial,-part-2\" data-toc-modified-id=\"AWK-tutorial,-part-2-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>AWK tutorial, part 2</a></span><ul class=\"toc-item\"><li><span><a href=\"#Matching-with-Regular-Expressions\" data-toc-modified-id=\"Matching-with-Regular-Expressions-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Matching with Regular Expressions</a></span></li><li><span><a href=\"#Comparisons-and-Logic\" data-toc-modified-id=\"Comparisons-and-Logic-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Comparisons and Logic</a></span></li><li><span><a href=\"#Built-in-Variables\" data-toc-modified-id=\"Built-in-Variables-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Built-in Variables</a></span></li><li><span><a href=\"#User-Defined-Variables\" data-toc-modified-id=\"User-Defined-Variables-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>User-Defined Variables</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWK tutorial, part 1\n",
    "https://blog.jpalardy.com/posts/awk-tutorial-part-1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the example data\n",
    "Jonathan Palardy provides a file with historical Netflix stock prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESTINATION=download/2020-01-24-awk-tutorial\n",
    "mkdir -p $DESTINATION\n",
    "cd $DESTINATION\n",
    "\n",
    "if [ ! -f netflix.tsv ]; then\n",
    "    curl -sO https://blog.jpalardy.com/assets/awk-tutorials/netflix.tsv\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions: cool stuff that we will be able to do with AWK soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `netflix.tsv` and also the processed output that we get for some of the examples in this notebook contain many lines. To enable us to focus on the important parts, we implement a bash function `snip` which can\n",
    "* read input from a pipe, or\n",
    "* take a file name as a parameter,\n",
    "\n",
    "and does the following:\n",
    "* if the input or the file contains 6 lines or less, print it as it is.\n",
    "* if it contains 7 lines or more, print the first 5 lines, then a line containing the text `...snip...`, and then the last line.\n",
    "\n",
    "The function is inspired by\n",
    "* https://stackoverflow.com/questions/11454343/pipe-output-to-bash-function/11457183#11457183\n",
    "* https://unix.stackexchange.com/questions/139089/how-to-read-first-and-last-line-from-cat-output/139099#139099\n",
    "\n",
    "After working through Jonathan's tutorial series, you should be able to understand how it works :-)\n",
    "\n",
    "Note that the variable `line`, which may look superfluous at first sight, was needed to prevent that the last line is printed twice if there are less then 6 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "snip() {\n",
    "    awk '{ line = $0 }; NR <= 5 { line = \"\"; print }; NR == 7 { print \"... snip ...\" }; END { print line }' \"$@\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how it processes data read from a pipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\tOpen\tHigh\tLow\tClose\tVolume\tAdj Close\n",
      "2016-03-24\t98.639999\t98.849998\t97.07\t98.360001\t10646900\t98.360001\n",
      "2016-03-23\t99.75\t100.389999\t98.809998\t99.589996\t8292300\t99.589996\n",
      "2016-03-22\t100.480003\t101.519997\t99.199997\t99.839996\t9039500\t99.839996\n",
      "2016-03-21\t101.150002\t102.099998\t99.50\t101.059998\t9562900\t101.059998\n",
      "... snip ...\n",
      "2002-05-23\t16.19\t17.399999\t16.04\t16.75\t104790000\t1.196429\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can also read files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\tOpen\tHigh\tLow\tClose\tVolume\tAdj Close\n",
      "2016-03-24\t98.639999\t98.849998\t97.07\t98.360001\t10646900\t98.360001\n",
      "2016-03-23\t99.75\t100.389999\t98.809998\t99.589996\t8292300\t99.589996\n",
      "2016-03-22\t100.480003\t101.519997\t99.199997\t99.839996\t9039500\t99.839996\n",
      "2016-03-21\t101.150002\t102.099998\t99.50\t101.059998\t9562900\t101.059998\n",
      "... snip ...\n",
      "2002-05-23\t16.19\t17.399999\t16.04\t16.75\t104790000\t1.196429\n"
     ]
    }
   ],
   "source": [
    "snip netflix.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, it will be useful to format the output such that columns are aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "format-and-snip () {\n",
    "    column -t \"$@\" | snip \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date        Open        High        Low         Close       Volume     Adj         Close\n",
      "2016-03-24  98.639999   98.849998   97.07       98.360001   10646900   98.360001\n",
      "2016-03-23  99.75       100.389999  98.809998   99.589996   8292300    99.589996\n",
      "2016-03-22  100.480003  101.519997  99.199997   99.839996   9039500    99.839996\n",
      "2016-03-21  101.150002  102.099998  99.50       101.059998  9562900    101.059998\n",
      "... snip ...\n",
      "2002-05-23  16.19       17.399999   16.04       16.75       104790000  1.196429\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | format-and-snip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date        Open        High        Low         Close       Volume     Adj         Close\n",
      "2016-03-24  98.639999   98.849998   97.07       98.360001   10646900   98.360001\n",
      "2016-03-23  99.75       100.389999  98.809998   99.589996   8292300    99.589996\n",
      "2016-03-22  100.480003  101.519997  99.199997   99.839996   9039500    99.839996\n",
      "2016-03-21  101.150002  102.099998  99.50       101.059998  9562900    101.059998\n",
      "... snip ...\n",
      "2002-05-23  16.19       17.399999   16.04       16.75       104790000  1.196429\n"
     ]
    }
   ],
   "source": [
    "format-and-snip netflix.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing Columns\n",
    "* `$1` is the content of the first column,\n",
    "* `$2` is the content of the second column, etc.\n",
    "* `$0` is the entire line.\n",
    "* Single quotes tell bash to keep string contents untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open\n",
      "98.639999\n",
      "99.75\n",
      "100.480003\n",
      "101.150002\n",
      "... snip ...\n",
      "16.19\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '{print $2}' | snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, awk can read the file instead of getting the content through a pipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open\n",
      "98.639999\n",
      "99.75\n",
      "100.480003\n",
      "101.150002\n",
      "... snip ...\n",
      "16.19\n"
     ]
    }
   ],
   "source": [
    "awk '{print $2}' netflix.tsv | snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of AWK rules\n",
    "An AWK program consists of *rules* which look like this:\n",
    "\n",
    "    condition { or or more statements }\n",
    "\n",
    "The action inside the curly braces is executed if the condition evaluates to *true*.\n",
    "\n",
    "Both the condition and the action are optional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatic conversions\n",
    "Strings are automatically converted to numbers if needed. **TODO:** Why is \"Open\" considered greater than 100?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open\n",
      "100.480003\n",
      "101.150002\n",
      "100.50\n",
      "101.00\n",
      "... snip ...\n",
      "100.009999\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '$2 > 100 { print $2 }' | snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing condition\n",
    "A missing condition causes the action to be executed always:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    }
   ],
   "source": [
    "echo 'A B C' | awk '{print $2}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is equivalent to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    }
   ],
   "source": [
    "echo 'A B C' | awk '1 {print $2}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing action\n",
    "The default action is to print the whole line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date        Open        High        Low         Close       Volume     Adj         Close\n",
      "2016-03-22  100.480003  101.519997  99.199997   99.839996   9039500    99.839996\n",
      "2016-03-21  101.150002  102.099998  99.50       101.059998  9562900    101.059998\n",
      "2016-03-18  100.50      102.410004  100.010002  101.120003  15437300   101.120003\n",
      "2016-03-07  101.00      101.790001  95.25       95.489998   23855200   95.489998\n",
      "... snip ...\n",
      "2010-04-23  100.009999  100.559999  96.360003   99.73       29817900   14.247143\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '$2 > 100' | format-and-snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default action is thus equivalent to `print` without arguments, which also prints the whole line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-24  98.639999  98.849998   97.07      98.360001   10646900   98.360001\n",
      "2016-03-16  97.529999  99.730003   97.50      99.349998   12598600   99.349998\n",
      "2016-03-15  97.870003  98.510002   96.43      97.860001   9678000    97.860001\n",
      "2016-03-14  97.199997  99.419998   97.169998  98.129997   11223200   98.129997\n",
      "2016-03-10  98.18      99.739998   95.449997  97.360001   16979400   97.360001\n",
      "... snip ...\n",
      "2002-05-23  16.19      17.399999   16.04      16.75       104790000  1.196429\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '$2 < 99 { print }' | format-and-snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`print $0` also prints the whole line because `$0` is a special variable which contains the current line, before it was split into fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-23  99.75      100.389999  98.809998  99.589996   8292300    99.589996\n",
      "2016-03-17  99.050003  101.389999  99.00      99.720001   13755000   99.720001\n",
      "2016-03-11  99.510002  99.599998   96.050003  97.660004   15097900   97.660004\n",
      "2016-01-26  99.739998  100.550003  94.849998  97.830002   22024700   97.830002\n",
      "2016-01-25  99.779999  102.68      99.00      99.120003   20250800   99.120003\n",
      "... snip ...\n",
      "2010-05-03  99.959998  103.809999  99.000003  101.989998  13974100   14.57\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '$2 >= 99 && $2 <= 100 { print $0 }' | format-and-snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Printing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing multiple columns\n",
    "A comma between print values will insert a space in the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Volume Close\n",
      "2016-03-24 10646900 98.360001\n",
      "2016-03-23 8292300 99.589996\n",
      "2016-03-22 9039500 99.839996\n",
      "2016-03-21 9562900 101.059998\n",
      "... snip ...\n",
      "2002-05-23 104790000 16.75\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '{print $1, $6, $5}' | snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More formatting power with `printf`\n",
    "`printf` provides functionality similar to the C function of the same name: https://linux.die.net/man/3/printf.\n",
    "\n",
    "Note that we use the condition `NR > 1` to remove the first line because the `f` format does not work well with the column headers.\n",
    "\n",
    "`NR` is a variable that contains the current line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-24        10646900 98.4\n",
      "2016-03-23         8292300 99.6\n",
      "2016-03-22         9039500 99.8\n",
      "2016-03-21         9562900 101.1\n",
      "2016-03-18        15437300 101.1\n",
      "... snip ...\n",
      "2002-05-23       104790000 16.8\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk 'NR > 1 {printf \"%s %15s %.1f\\n\", $1, $6, $5}' | snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String concatenation\n",
    "Putting two or more values next to each other in a `print` statement concatenates the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date,Volume\n",
      "2016-03-24,10646900\n",
      "2016-03-23,8292300\n",
      "2016-03-22,9039500\n",
      "2016-03-21,9562900\n",
      "... snip ...\n",
      "2002-05-23,104790000\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '{print $1 \",\" $6}' | snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the \"Date\", \"Volume\", \"Open\", \"Close\" columns, in that order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date        Volume     Open        Close\n",
      "2016-03-24  10646900   98.639999   98.360001\n",
      "2016-03-23  8292300    99.75       99.589996\n",
      "2016-03-22  9039500    100.480003  99.839996\n",
      "2016-03-21  9562900    101.150002  101.059998\n",
      "... snip ...\n",
      "2002-05-23  104790000  16.19       16.75\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '{print $1, $6, $2, $5}' | format-and-snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only print lines where the stock price increased (\"Close\" > \"Open\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-18  100.50      102.410004  100.010002  101.120003  15437300   101.120003\n",
      "2016-03-17  99.050003   101.389999  99.00       99.720001   13755000   99.720001\n",
      "2016-03-16  97.529999   99.730003   97.50       99.349998   12598600   99.349998\n",
      "2016-03-14  97.199997   99.419998   97.169998   98.129997   11223200   98.129997\n",
      "2016-03-09  96.82       98.370003   95.00       98.00       12279500   98.00\n",
      "... snip ...\n",
      "2002-05-23  16.19       17.399999   16.04       16.75       104790000  1.196429\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '$5 > $2' | format-and-snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe it's useful if we include the column headers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date        Open        High        Low         Close       Volume     Adj         Close\n",
      "2016-03-18  100.50      102.410004  100.010002  101.120003  15437300   101.120003\n",
      "2016-03-17  99.050003   101.389999  99.00       99.720001   13755000   99.720001\n",
      "2016-03-16  97.529999   99.730003   97.50       99.349998   12598600   99.349998\n",
      "2016-03-14  97.199997   99.419998   97.169998   98.129997   11223200   98.129997\n",
      "... snip ...\n",
      "2002-05-23  16.19       17.399999   16.04       16.75       104790000  1.196429\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk 'NR == 1 || $5 > $2' | format-and-snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the \"Date\" column and the stock price difference (\"Close\" - \"Open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-24  -0.279998\n",
      "2016-03-23  -0.160004\n",
      "2016-03-22  -0.640007\n",
      "2016-03-21  -0.090004\n",
      "2016-03-18  0.620003\n",
      "... snip ...\n",
      "2002-05-23  0.56\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk 'NR > 1 {print $1, $5 - $2}' | format-and-snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print an empty line between each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date        Open        High        Low         Close       Volume     Adj         Close\n",
      "\n",
      "2016-03-24  98.639999   98.849998   97.07       98.360001   10646900   98.360001\n",
      "\n",
      "2016-03-23  99.75       100.389999  98.809998   99.589996   8292300    99.589996\n",
      "\n",
      "2016-03-22  100.480003  101.519997  99.199997   99.839996   9039500    99.839996\n",
      "\n",
      "2016-03-21  101.150002  102.099998  99.50       101.059998  9562900    101.059998\n",
      "\n",
      "... snip ...\n",
      "\n",
      "2002-05-23  16.19       17.399999   16.04       16.75       104790000  1.196429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "format-and-snip netflix.tsv | awk '{ print $0 \"\\n\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWK tutorial, part 2\n",
    "https://blog.jpalardy.com/posts/awk-tutorial-part-2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching with Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to extract data from 2015. Note that a regular expression, by itself, is a shorthand for the condition `$0 ~ /regex/`.\n",
    "\n",
    "This means that\n",
    "    \n",
    "    awk '/^2015-/'\n",
    "\n",
    "is equivalent to\n",
    "\n",
    "    awk $0 ~ '/^2015-/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-12-31  116.209999  117.459999  114.279999  114.379997  9245000    114.379997\n",
      "2015-12-30  118.949997  119.019997  116.43      116.709999  8116200    116.709999\n",
      "2015-12-29  118.190002  119.599998  116.919998  119.120003  8159200    119.120003\n",
      "2015-12-28  117.260002  117.349998  113.849998  117.110001  8406300    117.110001\n",
      "2015-12-24  118.220001  118.800003  117.300003  117.330002  3531300    117.330002\n",
      "... snip ...\n",
      "2015-01-02  344.059998  352.32      341.12001   348.940002  13475000   49.848572\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '/^2015-/' | format-and-snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also match regular expressions on specific columns. This is how we extract lines where the \"Open\" column contains a value which is a multiple of $1 plus 63 cents: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-01-14  52.63\n",
      "2008-07-24  27.63\n",
      "2008-05-13  30.63\n",
      "2006-04-26  31.63\n",
      "2004-12-30  12.63\n",
      "... snip ...\n",
      "2002-08-22  13.63\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '$2 ~ /\\.63$/ { print $1 \"\\t\" $2}' | format-and-snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparisons and Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWK has the usual comparison operators `==`, `!=`, `>`, `>=`, `<`, `<=`.\n",
    "\n",
    "Moreover:\n",
    "* `$2 ~ /^10./` matches a column with a regex\n",
    "* `$2 !~ /^10./` is a negated regex match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expressions can be combined with the logical operators `&&` and `||`, and negated if prefixed with `!`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in Variables\n",
    "The most useful built-in variables are:\n",
    "* `NR`: the number of records (lines) processed since AWK started.\n",
    "* `NF`: the number of fields (columns) in the current line\n",
    "\n",
    "When working with multiple files, the following variables can come in handy:\n",
    "* `FNR`: like `NR`, but resets to 1 when it begins processing a new file\n",
    "* `FILENAME`: the name of the current file.\n",
    "\n",
    "More variables are documented at http://www.math.utah.edu/docs/info/gawk_11.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-Defined Variables\n",
    "A variable starts to exist when it is first used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO BE CONTINUED"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
