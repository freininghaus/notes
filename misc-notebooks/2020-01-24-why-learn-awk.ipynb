{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why learn AWK?\n",
    "This notebook is inspired by a very nice series of blog posts by Jonathan Palardy that I stumbled across recently:\n",
    "* https://blog.jpalardy.com/posts/why-learn-awk/\n",
    "* https://blog.jpalardy.com/posts/awk-tutorial-part-1/\n",
    "* https://blog.jpalardy.com/posts/awk-tutorial-part-2/\n",
    "* https://blog.jpalardy.com/posts/awk-tutorial-part-3/\n",
    "* https://blog.jpalardy.com/posts/my-best-awk-tricks/\n",
    "\n",
    "Maybe it makes sense to try awk after all :-)\n",
    "\n",
    "In this notebook, I'll reproduce the examples given in the blog posts, work on the exercises, and sometimes do a bit more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#AWK-tutorial,-part-1\" data-toc-modified-id=\"AWK-tutorial,-part-1-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>AWK tutorial, part 1</a></span><ul class=\"toc-item\"><li><span><a href=\"#Download-the-example-data\" data-toc-modified-id=\"Download-the-example-data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Download the example data</a></span></li><li><span><a href=\"#Helper-functions\" data-toc-modified-id=\"Helper-functions-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Helper functions</a></span></li><li><span><a href=\"#Printing-Columns\" data-toc-modified-id=\"Printing-Columns-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Printing Columns</a></span></li><li><span><a href=\"#Structure-of-AWK-rules\" data-toc-modified-id=\"Structure-of-AWK-rules-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Structure of AWK rules</a></span><ul class=\"toc-item\"><li><span><a href=\"#Automatic-conversions\" data-toc-modified-id=\"Automatic-conversions-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Automatic conversions</a></span></li><li><span><a href=\"#Missing-condition\" data-toc-modified-id=\"Missing-condition-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Missing condition</a></span></li><li><span><a href=\"#Missing-action\" data-toc-modified-id=\"Missing-action-1.4.3\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;</span>Missing action</a></span></li></ul></li><li><span><a href=\"#More-Printing\" data-toc-modified-id=\"More-Printing-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>More Printing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Printing-multiple-columns\" data-toc-modified-id=\"Printing-multiple-columns-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>Printing multiple columns</a></span></li><li><span><a href=\"#More-formatting-power-with-printf\" data-toc-modified-id=\"More-formatting-power-with-printf-1.5.2\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span>More formatting power with <code>printf</code></a></span></li><li><span><a href=\"#String-concatenation\" data-toc-modified-id=\"String-concatenation-1.5.3\"><span class=\"toc-item-num\">1.5.3&nbsp;&nbsp;</span>String concatenation</a></span></li></ul></li><li><span><a href=\"#Exercises\" data-toc-modified-id=\"Exercises-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Exercises</a></span><ul class=\"toc-item\"><li><span><a href=\"#Print-the-&quot;Date&quot;,-&quot;Volume&quot;,-&quot;Open&quot;,-&quot;Close&quot;-columns,-in-that-order\" data-toc-modified-id=\"Print-the-&quot;Date&quot;,-&quot;Volume&quot;,-&quot;Open&quot;,-&quot;Close&quot;-columns,-in-that-order-1.6.1\"><span class=\"toc-item-num\">1.6.1&nbsp;&nbsp;</span>Print the \"Date\", \"Volume\", \"Open\", \"Close\" columns, in that order</a></span></li><li><span><a href=\"#Only-print-lines-where-the-stock-price-increased-(&quot;Close&quot;->-&quot;Open&quot;)\" data-toc-modified-id=\"Only-print-lines-where-the-stock-price-increased-(&quot;Close&quot;->-&quot;Open&quot;)-1.6.2\"><span class=\"toc-item-num\">1.6.2&nbsp;&nbsp;</span>Only print lines where the stock price increased (\"Close\" &gt; \"Open\")</a></span></li><li><span><a href=\"#Print-the-&quot;Date&quot;-column-and-the-stock-price-difference-(&quot;Close&quot;---&quot;Open)\" data-toc-modified-id=\"Print-the-&quot;Date&quot;-column-and-the-stock-price-difference-(&quot;Close&quot;---&quot;Open)-1.6.3\"><span class=\"toc-item-num\">1.6.3&nbsp;&nbsp;</span>Print the \"Date\" column and the stock price difference (\"Close\" - \"Open)</a></span></li><li><span><a href=\"#Print-an-empty-line-between-each-line\" data-toc-modified-id=\"Print-an-empty-line-between-each-line-1.6.4\"><span class=\"toc-item-num\">1.6.4&nbsp;&nbsp;</span>Print an empty line between each line</a></span></li></ul></li></ul></li><li><span><a href=\"#AWK-tutorial,-part-2\" data-toc-modified-id=\"AWK-tutorial,-part-2-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>AWK tutorial, part 2</a></span><ul class=\"toc-item\"><li><span><a href=\"#Matching-with-Regular-Expressions\" data-toc-modified-id=\"Matching-with-Regular-Expressions-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Matching with Regular Expressions</a></span></li><li><span><a href=\"#Comparisons-and-Logic\" data-toc-modified-id=\"Comparisons-and-Logic-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Comparisons and Logic</a></span></li><li><span><a href=\"#Built-in-Variables\" data-toc-modified-id=\"Built-in-Variables-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Built-in Variables</a></span></li><li><span><a href=\"#User-Defined-Variables\" data-toc-modified-id=\"User-Defined-Variables-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>User-Defined Variables</a></span></li><li><span><a href=\"#Special-patterns:-BEGIN-and-END\" data-toc-modified-id=\"Special-patterns:-BEGIN-and-END-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Special patterns: <code>BEGIN</code> and <code>END</code></a></span></li><li><span><a href=\"#Blocks-and-Control:-next-and-exit\" data-toc-modified-id=\"Blocks-and-Control:-next-and-exit-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Blocks and Control: <code>next</code> and <code>exit</code></a></span></li><li><span><a href=\"#Exercises\" data-toc-modified-id=\"Exercises-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Exercises</a></span><ul class=\"toc-item\"><li><span><a href=\"#Only-print-lines-between-February-29,-2016-and-March-4,-2016\" data-toc-modified-id=\"Only-print-lines-between-February-29,-2016-and-March-4,-2016-2.7.1\"><span class=\"toc-item-num\">2.7.1&nbsp;&nbsp;</span>Only print lines between February 29, 2016 and March 4, 2016</a></span></li><li><span><a href=\"#Sum-the-volumes-for-all-days-of-January-2016\" data-toc-modified-id=\"Sum-the-volumes-for-all-days-of-January-2016-2.7.2\"><span class=\"toc-item-num\">2.7.2&nbsp;&nbsp;</span>Sum the volumes for all days of January 2016</a></span></li><li><span><a href=\"#Average-the-closing-price-over-all-days-of-March-2015\" data-toc-modified-id=\"Average-the-closing-price-over-all-days-of-March-2015-2.7.3\"><span class=\"toc-item-num\">2.7.3&nbsp;&nbsp;</span>Average the closing price over all days of March 2015</a></span></li><li><span><a href=\"#Check-that-all-lines-have-7-columns\" data-toc-modified-id=\"Check-that-all-lines-have-7-columns-2.7.4\"><span class=\"toc-item-num\">2.7.4&nbsp;&nbsp;</span>Check that <em>all</em> lines have 7 columns</a></span></li><li><span><a href=\"#Only-print-every-other-line-(say,-even-lines)\" data-toc-modified-id=\"Only-print-every-other-line-(say,-even-lines)-2.7.5\"><span class=\"toc-item-num\">2.7.5&nbsp;&nbsp;</span>Only print every other line (say, even lines)</a></span></li><li><span><a href=\"#Remove-empty-lines-in-a-file\" data-toc-modified-id=\"Remove-empty-lines-in-a-file-2.7.6\"><span class=\"toc-item-num\">2.7.6&nbsp;&nbsp;</span>Remove empty lines in a file</a></span></li></ul></li></ul></li><li><span><a href=\"#AWK-Tutorial,-part-3\" data-toc-modified-id=\"AWK-Tutorial,-part-3-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>AWK Tutorial, part 3</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWK tutorial, part 1\n",
    "https://blog.jpalardy.com/posts/awk-tutorial-part-1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the example data\n",
    "Jonathan Palardy provides a file with historical Netflix stock prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESTINATION=download/2020-01-24-awk-tutorial\n",
    "mkdir -p $DESTINATION\n",
    "cd $DESTINATION\n",
    "\n",
    "if [ ! -f netflix.tsv ]; then\n",
    "    curl -sO https://blog.jpalardy.com/assets/awk-tutorials/netflix.tsv\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `netflix.tsv` and also the processed output that we get for some of the examples in this notebook contain many lines. To enable us to focus on the important parts, we implement a bash function `snip` which can\n",
    "* read input from a pipe, or\n",
    "* take a file name as a parameter,\n",
    "\n",
    "and does the following:\n",
    "* if the input or the file contains 6 lines or less, print it as it is.\n",
    "* if it contains 7 lines or more, print the first 4 lines, then a line containing the text `# ... line(s) omitted` (where `...` is replaced by the number of omitted lines), and then the last 2 lines.\n",
    "\n",
    "Some information about the development of this function and source code with comments can be found in [a separate notebok](2020-01-26-head-plus-tail-with-awk.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "snip() {\n",
    "    awk -v HEAD=4 -v TAIL=2 '\n",
    "    NR <= HEAD { print; next }\n",
    "\n",
    "    { \n",
    "      if (tail_lines < TAIL)\n",
    "        tail_lines++\n",
    "      else\n",
    "        for (i = 1; i < tail_lines; i++)\n",
    "          last[i] = last[i+1]\n",
    "      last[tail_lines] = $0\n",
    "    }\n",
    "\n",
    "    END {\n",
    "      omitted = NR - (HEAD + TAIL)\n",
    "      if (omitted == 1)\n",
    "        print \"# 1 line omitted\"\n",
    "      else if (omitted > 0)\n",
    "        print \"# \" omitted \" lines omitted\"\n",
    "\n",
    "      for (i = 1; i <= tail_lines; i++)\n",
    "        print last[i]\n",
    "    }' \"$@\"\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how it processes data read from a pipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\tOpen\tHigh\tLow\tClose\tVolume\tAdj Close\n",
      "2016-03-24\t98.639999\t98.849998\t97.07\t98.360001\t10646900\t98.360001\n",
      "2016-03-23\t99.75\t100.389999\t98.809998\t99.589996\t8292300\t99.589996\n",
      "2016-03-22\t100.480003\t101.519997\t99.199997\t99.839996\t9039500\t99.839996\n",
      "# 3479 lines omitted\n",
      "2002-05-24\t17.00\t17.15\t16.76\t16.940001\t11104800\t1.21\n",
      "2002-05-23\t16.19\t17.399999\t16.04\t16.75\t104790000\t1.196429\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can also read files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\tOpen\tHigh\tLow\tClose\tVolume\tAdj Close\n",
      "2016-03-24\t98.639999\t98.849998\t97.07\t98.360001\t10646900\t98.360001\n",
      "2016-03-23\t99.75\t100.389999\t98.809998\t99.589996\t8292300\t99.589996\n",
      "2016-03-22\t100.480003\t101.519997\t99.199997\t99.839996\t9039500\t99.839996\n",
      "# 3479 lines omitted\n",
      "2002-05-24\t17.00\t17.15\t16.76\t16.940001\t11104800\t1.21\n",
      "2002-05-23\t16.19\t17.399999\t16.04\t16.75\t104790000\t1.196429\n"
     ]
    }
   ],
   "source": [
    "snip netflix.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, it will be useful to format the output such that columns are aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "format-and-snip () {\n",
    "    column -t \"$@\" | snip \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date        Open        High        Low         Close       Volume     Adj         Close\n",
      "2016-03-24  98.639999   98.849998   97.07       98.360001   10646900   98.360001\n",
      "2016-03-23  99.75       100.389999  98.809998   99.589996   8292300    99.589996\n",
      "2016-03-22  100.480003  101.519997  99.199997   99.839996   9039500    99.839996\n",
      "# 3479 lines omitted\n",
      "2002-05-24  17.00       17.15       16.76       16.940001   11104800   1.21\n",
      "2002-05-23  16.19       17.399999   16.04       16.75       104790000  1.196429\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | format-and-snip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date        Open        High        Low         Close       Volume     Adj         Close\n",
      "2016-03-24  98.639999   98.849998   97.07       98.360001   10646900   98.360001\n",
      "2016-03-23  99.75       100.389999  98.809998   99.589996   8292300    99.589996\n",
      "2016-03-22  100.480003  101.519997  99.199997   99.839996   9039500    99.839996\n",
      "# 3479 lines omitted\n",
      "2002-05-24  17.00       17.15       16.76       16.940001   11104800   1.21\n",
      "2002-05-23  16.19       17.399999   16.04       16.75       104790000  1.196429\n"
     ]
    }
   ],
   "source": [
    "format-and-snip netflix.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing Columns\n",
    "* `$1` is the content of the first column,\n",
    "* `$2` is the content of the second column, etc.\n",
    "* `$0` is the entire line.\n",
    "* Single quotes tell bash to keep string contents untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open\n",
      "98.639999\n",
      "99.75\n",
      "100.480003\n",
      "# 3479 lines omitted\n",
      "17.00\n",
      "16.19\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '{print $2}' | snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, awk can read the file instead of getting the content through a pipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open\n",
      "98.639999\n",
      "99.75\n",
      "100.480003\n",
      "# 3479 lines omitted\n",
      "17.00\n",
      "16.19\n"
     ]
    }
   ],
   "source": [
    "awk '{print $2}' netflix.tsv | snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of AWK rules\n",
    "An AWK program consists of *rules* which look like this:\n",
    "\n",
    "    condition { or or more statements }\n",
    "\n",
    "The action inside the curly braces is executed if the condition evaluates to *true*.\n",
    "\n",
    "Both the condition and the action are optional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatic conversions\n",
    "Strings are automatically converted to numbers if needed. **TODO:** Why is \"Open\" considered greater than 100?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open\n",
      "100.480003\n",
      "101.150002\n",
      "100.50\n",
      "# 1174 lines omitted\n",
      "100.440002\n",
      "100.009999\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '$2 > 100 { print $2 }' | snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing condition\n",
    "A missing condition causes the action to be executed always:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    }
   ],
   "source": [
    "echo 'A B C' | awk '{print $2}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is equivalent to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    }
   ],
   "source": [
    "echo 'A B C' | awk '1 {print $2}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing action\n",
    "The default action is to print the whole line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date        Open        High        Low         Close       Volume     Adj         Close\n",
      "2016-03-22  100.480003  101.519997  99.199997   99.839996   9039500    99.839996\n",
      "2016-03-21  101.150002  102.099998  99.50       101.059998  9562900    101.059998\n",
      "2016-03-18  100.50      102.410004  100.010002  101.120003  15437300   101.120003\n",
      "# 1174 lines omitted\n",
      "2010-04-26  100.440002  109.700001  100.440002  108.169999  47215000   15.452857\n",
      "2010-04-23  100.009999  100.559999  96.360003   99.73       29817900   14.247143\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '$2 > 100' | format-and-snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default action is thus equivalent to `print` without arguments, which also prints the whole line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-24  98.639999  98.849998   97.07      98.360001   10646900   98.360001\n",
      "2016-03-16  97.529999  99.730003   97.50      99.349998   12598600   99.349998\n",
      "2016-03-15  97.870003  98.510002   96.43      97.860001   9678000    97.860001\n",
      "2016-03-14  97.199997  99.419998   97.169998  98.129997   11223200   98.129997\n",
      "# 2283 lines omitted\n",
      "2002-05-24  17.00      17.15       16.76      16.940001   11104800   1.21\n",
      "2002-05-23  16.19      17.399999   16.04      16.75       104790000  1.196429\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '$2 < 99 { print }' | format-and-snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`print $0` also prints the whole line because `$0` is a special variable which contains the current line, before it was split into fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-23  99.75      100.389999  98.809998  99.589996   8292300    99.589996\n",
      "2016-03-17  99.050003  101.389999  99.00      99.720001   13755000   99.720001\n",
      "2016-03-11  99.510002  99.599998   96.050003  97.660004   15097900   97.660004\n",
      "2016-01-26  99.739998  100.550003  94.849998  97.830002   22024700   97.830002\n",
      "# 10 lines omitted\n",
      "2010-07-30  99.689999  103.179998  98.539999  102.549997  30704800   14.65\n",
      "2010-05-03  99.959998  103.809999  99.000003  101.989998  13974100   14.57\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '$2 >= 99 && $2 <= 100 { print $0 }' | format-and-snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Printing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing multiple columns\n",
    "A comma between print values will insert a space in the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Volume Close\n",
      "2016-03-24 10646900 98.360001\n",
      "2016-03-23 8292300 99.589996\n",
      "2016-03-22 9039500 99.839996\n",
      "# 3479 lines omitted\n",
      "2002-05-24 11104800 16.940001\n",
      "2002-05-23 104790000 16.75\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '{print $1, $6, $5}' | snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More formatting power with `printf`\n",
    "`printf` provides functionality similar to the C function of the same name: https://linux.die.net/man/3/printf.\n",
    "\n",
    "Note that we use the condition `NR > 1` to remove the first line because the `f` format does not work well with the column headers.\n",
    "\n",
    "`NR` is a variable that contains the current line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-24        10646900 98.4\n",
      "2016-03-23         8292300 99.6\n",
      "2016-03-22         9039500 99.8\n",
      "2016-03-21         9562900 101.1\n",
      "# 3478 lines omitted\n",
      "2002-05-24        11104800 16.9\n",
      "2002-05-23       104790000 16.8\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk 'NR > 1 {printf \"%s %15s %.1f\\n\", $1, $6, $5}' | snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String concatenation\n",
    "Putting two or more values next to each other in a `print` statement concatenates the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date,Volume\n",
      "2016-03-24,10646900\n",
      "2016-03-23,8292300\n",
      "2016-03-22,9039500\n",
      "# 3479 lines omitted\n",
      "2002-05-24,11104800\n",
      "2002-05-23,104790000\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '{print $1 \",\" $6}' | snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the \"Date\", \"Volume\", \"Open\", \"Close\" columns, in that order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date        Volume     Open        Close\n",
      "2016-03-24  10646900   98.639999   98.360001\n",
      "2016-03-23  8292300    99.75       99.589996\n",
      "2016-03-22  9039500    100.480003  99.839996\n",
      "# 3479 lines omitted\n",
      "2002-05-24  11104800   17.00       16.940001\n",
      "2002-05-23  104790000  16.19       16.75\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '{print $1, $6, $2, $5}' | format-and-snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only print lines where the stock price increased (\"Close\" > \"Open\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-18  100.50      102.410004  100.010002  101.120003  15437300   101.120003\n",
      "2016-03-17  99.050003   101.389999  99.00       99.720001   13755000   99.720001\n",
      "2016-03-16  97.529999   99.730003   97.50       99.349998   12598600   99.349998\n",
      "2016-03-14  97.199997   99.419998   97.169998   98.129997   11223200   98.129997\n",
      "# 1692 lines omitted\n",
      "2002-06-03  15.120001   16.089999   15.069999   15.799999   3151400    1.128571\n",
      "2002-05-23  16.19       17.399999   16.04       16.75       104790000  1.196429\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '$5 > $2' | format-and-snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe it's useful if we include the column headers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date        Open        High        Low         Close       Volume     Adj         Close\n",
      "2016-03-18  100.50      102.410004  100.010002  101.120003  15437300   101.120003\n",
      "2016-03-17  99.050003   101.389999  99.00       99.720001   13755000   99.720001\n",
      "2016-03-16  97.529999   99.730003   97.50       99.349998   12598600   99.349998\n",
      "# 1693 lines omitted\n",
      "2002-06-03  15.120001   16.089999   15.069999   15.799999   3151400    1.128571\n",
      "2002-05-23  16.19       17.399999   16.04       16.75       104790000  1.196429\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk 'NR == 1 || $5 > $2' | format-and-snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the \"Date\" column and the stock price difference (\"Close\" - \"Open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-24  -0.279998\n",
      "2016-03-23  -0.160004\n",
      "2016-03-22  -0.640007\n",
      "2016-03-21  -0.090004\n",
      "# 3478 lines omitted\n",
      "2002-05-24  -0.059999\n",
      "2002-05-23  0.56\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk 'NR > 1 {print $1, $5 - $2}' | format-and-snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print an empty line between each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date        Open        High        Low         Close       Volume     Adj         Close\n",
      "\n",
      "2016-03-24  98.639999   98.849998   97.07       98.360001   10646900   98.360001\n",
      "\n",
      "2016-03-23  99.75       100.389999  98.809998   99.589996   8292300    99.589996\n",
      "\n",
      "2016-03-22  100.480003  101.519997  99.199997   99.839996   9039500    99.839996\n",
      "\n",
      "# 3479 lines omitted\n",
      "\n",
      "2002-05-24  17.00       17.15       16.76       16.940001   11104800   1.21\n",
      "\n",
      "2002-05-23  16.19       17.399999   16.04       16.75       104790000  1.196429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "format-and-snip netflix.tsv | awk '{ print $0 \"\\n\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWK tutorial, part 2\n",
    "https://blog.jpalardy.com/posts/awk-tutorial-part-2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching with Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to extract data from 2015. Note that a regular expression, by itself, is a shorthand for the condition `$0 ~ /regex/`.\n",
    "\n",
    "This means that\n",
    "    \n",
    "    awk '/^2015-/'\n",
    "\n",
    "is equivalent to\n",
    "\n",
    "    awk $0 ~ '/^2015-/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-12-31  116.209999  117.459999  114.279999  114.379997  9245000    114.379997\n",
      "2015-12-30  118.949997  119.019997  116.43      116.709999  8116200    116.709999\n",
      "2015-12-29  118.190002  119.599998  116.919998  119.120003  8159200    119.120003\n",
      "2015-12-28  117.260002  117.349998  113.849998  117.110001  8406300    117.110001\n",
      "# 246 lines omitted\n",
      "2015-01-05  344.810001  344.810001  330.03001   331.179996  18165000   47.311428\n",
      "2015-01-02  344.059998  352.32      341.12001   348.940002  13475000   49.848572\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '/^2015-/' | format-and-snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also match regular expressions on specific columns. This is how we extract lines where the \"Open\" column contains a value which is a multiple of $1 plus 63 cents: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-01-14  52.63\n",
      "2008-07-24  27.63\n",
      "2008-05-13  30.63\n",
      "2006-04-26  31.63\n",
      "# 2 lines omitted\n",
      "2003-02-28  16.63\n",
      "2002-08-22  13.63\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '$2 ~ /\\.63$/ { print $1 \"\\t\" $2}' | format-and-snip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparisons and Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AWK has the usual comparison operators `==`, `!=`, `>`, `>=`, `<`, `<=`.\n",
    "\n",
    "Moreover:\n",
    "* `$2 ~ /^10./` matches a column with a regex\n",
    "* `$2 !~ /^10./` is a negated regex match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expressions can be combined with the logical operators `&&` and `||`, and negated if prefixed with `!`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in Variables\n",
    "The most useful built-in variables are:\n",
    "* `NR`: the number of records (lines) processed since AWK started.\n",
    "* `NF`: the number of fields (columns) in the current line\n",
    "\n",
    "When working with multiple files, the following variables can come in handy:\n",
    "* `FNR`: like `NR`, but resets to 1 when it begins processing a new file\n",
    "* `FILENAME`: the name of the current file.\n",
    "\n",
    "More variables are documented at http://www.math.utah.edu/docs/info/gawk_11.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-Defined Variables\n",
    "A variable starts to exist when it is first used. A previously undefined variable contains the empty string (see below for the meaning of `BEGIN`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of x is \"\"\n"
     ]
    }
   ],
   "source": [
    "awk 'BEGIN { print \"The value of x is \\\"\" x \"\\\"\" }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned earlier, strings are converted to numbers if needed. The empty string is converted to zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numerical value of an uninitialized number is 0.\n"
     ]
    }
   ],
   "source": [
    "awk 'BEGIN { print \"The numerical value of an uninitialized number is \" x + 0 \".\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "awk 'BEGIN { x = x + 2; print x }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special patterns: `BEGIN` and `END`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are special conditions that get triggered exactly once (even if there are no input lines):\n",
    "* `BEGIN` gets triggered *before* processing any line. Common use-cases are:\n",
    "    * initialization of variables,\n",
    "    * printing a header.\n",
    "* `END` get triggered *after* all lines have been processed. It is often used to calculate a result and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3485\n"
     ]
    }
   ],
   "source": [
    "# reproduce the result of wc -l\n",
    "cat netflix.tsv | awk 'END { print NR }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocks and Control: `next` and `exit`\n",
    "If there are multiple condition-block pairs, each of them is applied to every input line (except for the special cases `BEGIN` and `END`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-24\t98.639999\t98.849998\t97.07\t98.360001\t10646900\t98.360001\n",
      "2016-03-15\t97.870003\t98.510002\t96.43\t97.860001\t9678000\t97.860001\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '/^2016-03-24/; $4 == 96.43'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if there is a line that matches both conditions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-24\t98.639999\t98.849998\t97.07\t98.360001\t10646900\t98.360001\n",
      "2016-03-24\t98.639999\t98.849998\t97.07\t98.360001\t10646900\t98.360001\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '/^2016-03-24/; $4 == 97.07'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use a single block, and combine both conditions into one with `&&`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-24\t98.639999\t98.849998\t97.07\t98.360001\t10646900\t98.360001\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '/^2016-03-24/ && $4 == 97.07'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if two separate condition-block pairs are needed, and it is not easily possible to make the conditions mutually exlusive, we can use the `next` statement, which will make awk go to the next input line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-24\t98.639999\t98.849998\t97.07\t98.360001\t10646900\t98.360001\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '/^2016-03-24/ { print; next } $4 == 97.07'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also an `exit` statement, which will execute the `END` block if there is one, and then exit the script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-24\t98.639999\t98.849998\t97.07\t98.360001\t10646900\t98.360001\n"
     ]
    }
   ],
   "source": [
    "# Find the first line from 2016.\n",
    "# Note that we avoid cat and pipes here to avoid a 'broken pipe' error.\n",
    "awk '/^2016-/ { print; exit }' netflix.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only print lines between February 29, 2016 and March 4, 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-03-04  98.760002  102.220001  98.32      101.580002  23388400  101.580002\n",
      "2016-03-03  97.830002  98.349998   95.389999  97.93       15303600  97.93\n",
      "2016-03-02  98.010002  99.480003   95.900002  97.610001   19088400  97.610001\n",
      "2016-03-01  94.580002  99.160004   93.610001  98.300003   16997700  98.300003\n",
      "2016-02-29  94.809998  97.199997   93.339996  93.410004   13157100  93.410004\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '$1 >= \"2016-02-29\" && $1 <= \"2016-03-04\"' | column -t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sum the volumes for all days of January 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484411300\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '\n",
    "    $1 ~ /^2016-01/ { sum += $6 }\n",
    "    END { print sum }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average the closing price over all days of March 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437.661\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '\n",
    "    $1 >= \"2015-03-01\" && $1 <= \"2015-03-31\" { count++; sum += $5 }\n",
    "    END { print sum / count }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that *all* lines have 7 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This line has 8 columns, not 7: Date\tOpen\tHigh\tLow\tClose\tVolume\tAdj Close\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk 'NF != 7 { print \"This line has \" NF \" columns, not 7: \" $0 }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how often each column count occurs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3484 lines have 7 columns\n",
      "      1 lines have 8 columns\n"
     ]
    }
   ],
   "source": [
    "cat netflix.tsv | awk '{ print \"lines have\", NF, \"columns\" }' | sort -n | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only print every other line (say, even lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat netflix.tsv | awk 'NR % 2 == 0 { $0 }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove empty lines in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first line\n",
      "\n",
      "last line\n"
     ]
    }
   ],
   "source": [
    "printf \"first line\\n\\nlast line\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first line\n",
      "last line\n"
     ]
    }
   ],
   "source": [
    "printf \"first line\\n\\nlast line\\n\" | awk '$0 != \"\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative solution with a regular expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first line\n",
      "last line\n"
     ]
    }
   ],
   "source": [
    "printf \"first line\\n\\nlast line\\n\" | awk '! /^$/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even easier: check if there are more than zero columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first line\n",
      "last line\n"
     ]
    }
   ],
   "source": [
    "printf \"first line\\n\\nlast line\\n\" | awk 'NF'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWK Tutorial, part 3\n",
    "https://blog.jpalardy.com/posts/awk-tutorial-part-3/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO BE CONTINUED"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
